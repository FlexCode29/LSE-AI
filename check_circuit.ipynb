{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a76d69a1-ce05-470b-b9ea-84dd9824d9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2490/1995519283.py:54: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"load_ext autoreload\")\n",
      "/tmp/ipykernel_2490/1995519283.py:55: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"autoreload 2\")\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch as t\n",
    "from easy_transformer.EasyTransformer import (\n",
    "    EasyTransformer,\n",
    ")\n",
    "from time import ctime\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from easy_transformer.experiments import (\n",
    "    ExperimentMetric,\n",
    "    AblationConfig,\n",
    "    EasyAblation,\n",
    "    EasyPatching,\n",
    "    PatchingConfig,\n",
    ")\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import random\n",
    "import einops\n",
    "from IPython import get_ipython\n",
    "from copy import deepcopy\n",
    "from easy_transformer.ioi_dataset import (\n",
    "    IOIDataset,\n",
    ")\n",
    "from easy_transformer.ioi_utils import (\n",
    "    path_patching,\n",
    "    max_2d,\n",
    "    CLASS_COLORS,\n",
    "    show_pp,\n",
    "    show_attention_patterns,\n",
    "    scatter_attention_and_contribution,\n",
    ")\n",
    "from random import randint as ri\n",
    "from easy_transformer.ioi_circuit_extraction import (\n",
    "    do_circuit_extraction,\n",
    "    get_heads_circuit,\n",
    "    CIRCUIT,\n",
    ")\n",
    "from easy_transformer.ioi_utils import logit_diff, probs\n",
    "from easy_transformer.ioi_utils import get_top_tokens_and_probs as g\n",
    "\n",
    "ipython = get_ipython()\n",
    "if ipython is not None:\n",
    "    ipython.magic(\"load_ext autoreload\")\n",
    "    ipython.magic(\"autoreload 2\")\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f86e70d-7b98-4720-ab46-0d69360d5fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICL_dataset:\n",
    "    def __init__(self, input, labels, N):\n",
    "        self.input = input\n",
    "        self.labels = labels\n",
    "        self.N = N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "625b3a5b-b9b8-43c9-8d77-90eac50eab6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Finished loading pretrained model gpt2 into EasyTransformer!\n"
     ]
    }
   ],
   "source": [
    "model = EasyTransformer.from_pretrained(\"gpt2\")\n",
    "model.set_use_attn_result(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3882bde8-10f9-4f93-8615-25497560aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(model, device, x_initial, y_initial, icl_length, n, offset=0):\n",
    "    prompts = []\n",
    "    correct_answers = []\n",
    "    # Initialize x and y for the sequence\n",
    "    x, y = x_initial + offset, y_initial + offset\n",
    "\n",
    "\n",
    "    for i in range(n):\n",
    "        prompt = ''\n",
    "        for j in range(icl_length + 1):\n",
    "            if j < icl_length:\n",
    "                prompt += f\"Input: {j}, Output: {j * x + y}\\n\"\n",
    "            else:\n",
    "                prompt += f\"Input: {j}, Output:\"\n",
    "                correct_answers.append(j * x + y)  # Record the correct answer for the last input\n",
    "        prompts.append(prompt)\n",
    "        # Update x and y after generating each full prompt set\n",
    "        if i % 2 == 0:\n",
    "            x += 1\n",
    "        else:\n",
    "            y += 1\n",
    "\n",
    "\n",
    "    # Convert prompts into tokens\n",
    "    data_tokens = [model.to_tokens(prompt).to(device) for prompt in prompts]\n",
    "    correct_answers_tensor = torch.tensor(correct_answers).to(torch.double).unsqueeze(-1).to(device)\n",
    "    return ICL_dataset(input=prompts, labels=correct_answers_tensor, N=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df6de23d-52e1-4803-a984-0efd8edae43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_metric(model, dataset, device='cpu', return_one_element = False):\n",
    "        # dataset: {input: data, labels: correct, }\n",
    "        logits = model(dataset.input, return_type=\"logits\")\n",
    "    \n",
    "    \n",
    "        # Select the logits for the last token in each sequence\n",
    "        # model_output shape: [batch_size, seq_length, vocab_size] => [10, 103, 50257]\n",
    "        # We select [:, -1, :] to get the last token logits for each example in the batch\n",
    "        last_token_logits = logits[:, -1, :]  # Shape: [10, 50257]\n",
    "    \n",
    "        # Now, find the indices of the 10 highest logits for the last token across the batch\n",
    "        # We use torch.topk to get the top 10 logits' indices for each example\n",
    "        topk_values, topk_indices = torch.topk(last_token_logits, 1, dim=1) \n",
    "\n",
    "        predictions = model.to_str_tokens(topk_indices)\n",
    "        predictions = torch.tensor([int(pred) for pred in predictions]).to(torch.double).unsqueeze(-1).to(device)\n",
    "\n",
    "        # Calculate MSE\n",
    "        mse = F.mse_loss(predictions, dataset.labels, reduction='mean' if not return_one_element else 'sum')\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "feb1ea28-4ec8-41bb-98c7-8af7dd74e1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.7000, dtype=torch.float64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_validation_metric(device, model, x_initial, y_initial, icl_length, n):\n",
    "        dataset = generate_data(model, device, x_initial, y_initial, icl_length, n)\n",
    "        mse = validation_metric(model, dataset)\n",
    "        \n",
    "        return mse\n",
    "        print('This is the MSE: ', mse)\n",
    "test_validation_metric('cpu', model, 2, 1, 12, 10)  # 5.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f96e2ee-f3ef-4196-8734-af3b8e5455b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name mover': [(9, 9),\n",
       "  (10, 0),\n",
       "  (9, 6),\n",
       "  (10, 10),\n",
       "  (10, 6),\n",
       "  (10, 2),\n",
       "  (10, 1),\n",
       "  (11, 2),\n",
       "  (9, 7),\n",
       "  (9, 0),\n",
       "  (11, 9)],\n",
       " 'negative': [(10, 7), (11, 10)],\n",
       " 's2 inhibition': [(7, 3), (7, 9), (8, 6), (8, 10)],\n",
       " 'induction': [(5, 5), (5, 8), (5, 9), (6, 9)],\n",
       " 'duplicate token': [(0, 1), (0, 10), (3, 0)],\n",
       " 'previous token': [(2, 2), (4, 11)]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CIRCUIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72d78fe8-6e59-4010-9312-e7b3e7ede9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ICL_CIRCUIT = {\n",
    "  'operating': [(8, 1), (6, 9), (5, 0), (8, 9), (9, 11), (9, 2), (7, 7), (5, 2), (4, 8), (5, 1), (3, 4), (4, 3), (9, 9), (8, 11), (6, 10), (8, 8), (6, 0), (9, 5), (6, 3), (8, 6), (6, 7), (6, 6), (7, 6), (6, 2), (7, 10), (9, 1), (1, 9), (10, 2), (5, 11), (8, 7), (0, 1), (0, 3), (0, 5), (7, 11), (7, 2), (6, 1), (0, 8), (0, 7), (0, 6), (0, 4), (5, 5)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246f7c1e-4904-46eb-adc6-e442ccf97abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_circuit_extraction(\n",
    "    heads_to_remove=None,  # {(2,3) : List[List[int]]: dimensions dataset_size * datapoint_length\n",
    "    mlps_to_remove=None,  # {2: List[List[int]]: dimensions dataset_size * datapoint_length\n",
    "    heads_to_keep=None,  # as above for heads\n",
    "    mlps_to_keep=None,  # as above for mlps\n",
    "    ioi_dataset=None,\n",
    "    mean_dataset=None,\n",
    "    model=None,\n",
    "    metric=None,\n",
    "    excluded=[],  # tuple of (layer, head) or (layer, None for MLPs)\n",
    "    return_hooks=False,\n",
    "    hooks_dict=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    ..._to_remove means the indices ablated away. Otherwise the indices not ablated away.\n",
    "\n",
    "    `exclude_heads` is a list of heads that actually we won't put any hooks on. Just keep them as is\n",
    "\n",
    "    if `mean_dataset` is None, just use the ioi_dataset for mean\n",
    "    \"\"\"\n",
    "\n",
    "    # check if we are either in keep XOR remove move from the args\n",
    "    ablation, heads, mlps = get_circuit_replacement_hook(\n",
    "        heads_to_remove=heads_to_remove,  # {(2,3) : List[List[int]]: dimensions dataset_size * datapoint_length\n",
    "        mlps_to_remove=mlps_to_remove,  # {2: List[List[int]]: dimensions dataset_size * datapoint_length\n",
    "        heads_to_keep=heads_to_keep,  # as above for heads\n",
    "        mlps_to_keep=mlps_to_keep,  # as above for mlps\n",
    "        ioi_dataset=ioi_dataset,\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "    metric = ExperimentMetric(\n",
    "        metric=metric, dataset=ioi_dataset.sentences, relative_metric=False\n",
    "    )  # TODO make dummy metric\n",
    "\n",
    "    if mean_dataset is None:\n",
    "        mean_dataset = ioi_dataset\n",
    "\n",
    "    config = AblationConfig(\n",
    "        abl_type=\"custom\",\n",
    "        abl_fn=ablation,\n",
    "        mean_dataset=mean_dataset.toks.long(),  # TODO nb of prompts useless ?\n",
    "        target_module=\"attn_head\",\n",
    "        head_circuit=\"result\",\n",
    "        cache_means=True,  # circuit extraction *has* to cache means. the get_mean reset the\n",
    "        verbose=True,\n",
    "    )\n",
    "    abl = EasyAblation(\n",
    "        model,\n",
    "        config,\n",
    "        metric,\n",
    "        semantic_indices=None,  # ioi_dataset.sem_tok_idx,\n",
    "        mean_by_groups=True,  # TO CHECK CIRCUIT BY GROUPS\n",
    "        groups=ioi_dataset.groups,\n",
    "    )\n",
    "    model.reset_hooks()\n",
    "\n",
    "    hooks = {}\n",
    "\n",
    "    heads_keys = list(heads.keys())\n",
    "    # sort in lexicographic order\n",
    "    heads_keys.sort(key=lambda x: (x[0], x[1]))\n",
    "\n",
    "    for (\n",
    "        layer,\n",
    "        head,\n",
    "    ) in heads_keys:  # a sketchy edit here didn't really improve things : (\n",
    "        if (layer, head) in excluded:\n",
    "            continue\n",
    "        assert (layer, head) not in hooks, ((layer, head), \"already in hooks\")\n",
    "        hooks[(layer, head)] = abl.get_hook(layer, head)\n",
    "        # model.add_hook(*abl.get_hook(layer, head))\n",
    "    for layer in mlps.keys():\n",
    "        hooks[(layer, None)] = abl.get_hook(layer, head=None, target_module=\"mlp\")\n",
    "        # model.add_hook(*abl.get_hook(layer, head=None, target_module=\"mlp\"))\n",
    "\n",
    "    if return_hooks:\n",
    "        if hooks_dict:\n",
    "            return hooks\n",
    "        else:\n",
    "            return list(hooks.values())\n",
    "\n",
    "    else:\n",
    "        for hook in hooks.values():\n",
    "            model.add_hook(*hook)\n",
    "        return model, abl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
