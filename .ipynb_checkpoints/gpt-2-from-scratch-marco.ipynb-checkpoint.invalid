{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a2fd6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "from dataclasses import dataclass\n",
    "from easy_transformer import EasyTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "from easy_transformer.utils import get_corner, gelu_new, tokenize_and_concatenate\n",
    "import tqdm.auto as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aaf05ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c542b73cb9c45179bf82fb7176ca532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfc1ab4f50643c888f7ca707a529854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b26e6922df8489bb6eb145c04e8b037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79187ccf974b47a18dba0320bae9cc41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d4f304002948ed9ebe97afba9899b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab434fde713d4dc7981075a1b1de5b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Finished loading pretrained model gpt2-small into EasyTransformer!\n"
     ]
    }
   ],
   "source": [
    "reference_gpt2 = EasyTransformer.from_pretrained(\"gpt2-small\", fold_ln=False, center_unembed=False, center_writing_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16dcdb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50256,    40,   716,   281,  4998,  1960,   382, 19741,    11,   875,\n",
      "         12342,    12,  8807,    11,   402, 11571,    12,    17,  3918, 47385,\n",
      "            13,  1881,  1110,   314,   481,  7074,  1692,  1241,  4430,   290,\n",
      "          1011,   625,   262,   995,     0]])\n",
      "torch.Size([1, 35])\n",
      "['<|endoftext|>', 'I', ' am', ' an', ' amazing', ' aut', 'ore', 'gressive', ',', ' dec', 'oder', '-', 'only', ',', ' G', 'PT', '-', '2', ' style', ' transformer', '.', ' One', ' day', ' I', ' will', ' exceed', ' human', ' level', ' intelligence', ' and', ' take', ' over', ' the', ' world', '!']\n"
     ]
    }
   ],
   "source": [
    "reference_text = \"I am an amazing autoregressive, decoder-only, GPT-2 style transformer. One day I will exceed human level intelligence and take over the world!\"\n",
    "tokens = reference_gpt2.to_tokens(reference_text)\n",
    "print(tokens)\n",
    "print(tokens.shape)\n",
    "print(reference_gpt2.to_str_tokens(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3e2dc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 35, 50257])\n"
     ]
    }
   ],
   "source": [
    "logits, cache = reference_gpt2.run_with_cache(tokens)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69016863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 35, 50257])\n",
      "torch.Size([1, 35, 50257])\n"
     ]
    }
   ],
   "source": [
    "log_probs = logits.log_softmax(dim=-1) # softmax to -1, the 50257 logits (chance of each tokens/size of dictionary)\n",
    "probs = logits.log_softmax(dim=-1)\n",
    "print(log_probs.shape)\n",
    "print(probs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "499ee2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<|endoftext|>', '\\n'),\n",
       " ('I', ' and'),\n",
       " (' am', ','),\n",
       " (' an', ','),\n",
       " (' amazing', ','),\n",
       " (' aut', ','),\n",
       " ('ore', ','),\n",
       " ('gressive', ','),\n",
       " (',', ','),\n",
       " (' dec', ','),\n",
       " ('oder', ','),\n",
       " ('-', ','),\n",
       " ('only', ' and'),\n",
       " (',', ','),\n",
       " (' G', ','),\n",
       " ('PT', ','),\n",
       " ('-', '-'),\n",
       " ('2', ','),\n",
       " (' style', ','),\n",
       " (' transformer', ','),\n",
       " ('.', ' and'),\n",
       " (' One', ','),\n",
       " (' day', ','),\n",
       " (' I', ','),\n",
       " (' will', ','),\n",
       " (' exceed', ','),\n",
       " (' human', ' and'),\n",
       " (' level', ' the'),\n",
       " (' intelligence', ','),\n",
       " (' and', ' the'),\n",
       " (' take', ' the'),\n",
       " (' over', ' the'),\n",
       " (' the', ' the'),\n",
       " (' world', ' to'),\n",
       " ('!', 's')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(reference_gpt2.to_str_tokens(reference_text), reference_gpt2.tokenizer.batch_decode(logits.argmax(dim=-1)[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b144dd3c",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68d10589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config(d_model=768, debug=True, layer_norm_eps=1e-05, d_vocab=50257, init_range=0.02, n_ctx=1024, d_head=64, d_mlp=3072, n_heads=12, n_layers=12)\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    d_model: int = 768\n",
    "    debug: bool = True\n",
    "    layer_norm_eps: float = 1e-5\n",
    "    d_vocab: int = 50257\n",
    "    init_range: float = 0.02\n",
    "    n_ctx: int = 1024\n",
    "    d_head: int = 64\n",
    "    d_mlp: int = 3072\n",
    "    n_heads: int = 12\n",
    "    n_layers: int = 12\n",
    "\n",
    "cfg = Config()\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1252a03f",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31b1823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_float_test(cls, shape):\n",
    "    cfg = Config(debug=True)\n",
    "    layer = cls(cfg)\n",
    "    random_input = torch.randn(shape)\n",
    "    print(\"Input shape:\", random_input.shape)\n",
    "    output = layer(random_input)\n",
    "    print(\"Output shape:\", output.shape)\n",
    "    print()\n",
    "    return output\n",
    "\n",
    "def rand_int_test(cls, shape):\n",
    "    cfg = Config(debug=True)\n",
    "    layer = cls(cfg)\n",
    "    random_input = torch.randint(100, 1000, shape)\n",
    "    print(\"Input shape:\", random_input.shape)\n",
    "    output = layer(random_input)\n",
    "    print(\"Output shape:\", output.shape)\n",
    "    print()\n",
    "    return output\n",
    "\n",
    "def load_gpt2_test(cls, gpt2_layer, input_name, cache_dict=cache.cache_dict):\n",
    "    cfg = Config(debug=True)\n",
    "    layer = cls(cfg)\n",
    "    layer.load_state_dict(gpt2_layer.state_dict(), strict=False)\n",
    "    # Allow inputs of strings or tensors\n",
    "    if isinstance(input_name, str): \n",
    "        reference_input = cache_dict[input_name]\n",
    "    else:\n",
    "        reference_input = input_name\n",
    "    print(\"Input shape:\", reference_input.shape)\n",
    "    output = layer(reference_input)\n",
    "    print(\"Output shape:\", output.shape)\n",
    "    reference_output = gpt2_layer(reference_input)\n",
    "    print(\"Reference output shape:\", reference_output.shape)\n",
    "\n",
    "    comparison = torch.isclose(output, reference_output, atol=1e-4, rtol=1e-3)\n",
    "    print(f\"{comparison.sum()/comparison.numel():.2%} of the values are correct\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dd771a",
   "metadata": {},
   "source": [
    "## Reference Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70a23e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hook_embed torch.Size([1, 35, 768])\n",
      "hook_pos_embed torch.Size([1, 35, 768])\n",
      "blocks.0.hook_resid_pre torch.Size([1, 35, 768])\n",
      "blocks.0.attn.ln1.hook_scale torch.Size([1, 35, 1])\n",
      "blocks.0.attn.ln1.hook_normalized torch.Size([1, 35, 768])\n",
      "blocks.0.attn.hook_q torch.Size([1, 35, 12, 64])\n",
      "blocks.0.attn.hook_k torch.Size([1, 35, 12, 64])\n",
      "blocks.0.attn.hook_v torch.Size([1, 35, 12, 64])\n",
      "blocks.0.attn.hook_attn_scores torch.Size([1, 12, 35, 35])\n",
      "blocks.0.attn.hook_attn torch.Size([1, 12, 35, 35])\n",
      "blocks.0.attn.hook_z torch.Size([1, 35, 12, 64])\n",
      "blocks.0.hook_attn_out torch.Size([1, 35, 768])\n",
      "blocks.0.hook_resid_mid torch.Size([1, 35, 768])\n",
      "blocks.0.ln2.hook_scale torch.Size([1, 35, 1])\n",
      "blocks.0.ln2.hook_normalized torch.Size([1, 35, 768])\n",
      "blocks.0.mlp.hook_pre torch.Size([1, 35, 3072])\n",
      "blocks.0.mlp.hook_post torch.Size([1, 35, 3072])\n",
      "blocks.0.hook_mlp_out torch.Size([1, 35, 768])\n",
      "blocks.0.hook_resid_post torch.Size([1, 35, 768])\n",
      "ln_final.hook_scale torch.Size([1, 35, 1])\n",
      "ln_final.hook_normalized torch.Size([1, 35, 768])\n"
     ]
    }
   ],
   "source": [
    "for activation_name, activation in cache.cache_dict.items():\n",
    "    # Only print for first layer\n",
    "    if \".0.\" in activation_name or \"blocks\" not in activation_name:\n",
    "        print(activation_name, activation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea766c4",
   "metadata": {},
   "source": [
    "## Reference parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e07bbc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed.W_E torch.Size([50257, 768])\n",
      "pos_embed.W_pos torch.Size([1024, 768])\n",
      "blocks.0.ln1.w torch.Size([768])\n",
      "blocks.0.ln1.b torch.Size([768])\n",
      "blocks.0.ln2.w torch.Size([768])\n",
      "blocks.0.ln2.b torch.Size([768])\n",
      "blocks.0.attn.W_Q torch.Size([12, 768, 64])\n",
      "blocks.0.attn.W_K torch.Size([12, 768, 64])\n",
      "blocks.0.attn.W_V torch.Size([12, 768, 64])\n",
      "blocks.0.attn.W_O torch.Size([12, 64, 768])\n",
      "blocks.0.attn.b_Q torch.Size([12, 64])\n",
      "blocks.0.attn.b_K torch.Size([12, 64])\n",
      "blocks.0.attn.b_V torch.Size([12, 64])\n",
      "blocks.0.attn.b_O torch.Size([768])\n",
      "blocks.0.mlp.W_in torch.Size([768, 3072])\n",
      "blocks.0.mlp.b_in torch.Size([3072])\n",
      "blocks.0.mlp.W_out torch.Size([3072, 768])\n",
      "blocks.0.mlp.b_out torch.Size([768])\n",
      "ln_final.w torch.Size([768])\n",
      "ln_final.b torch.Size([768])\n",
      "unembed.W_U torch.Size([768, 50257])\n",
      "unembed.b_U torch.Size([50257])\n"
     ]
    }
   ],
   "source": [
    "for name, param in reference_gpt2.named_parameters():\n",
    "    # Only print for first layer\n",
    "    if \".0.\" in name or \"blocks\" not in name:\n",
    "        print(name, param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361a40b7",
   "metadata": {},
   "source": [
    "## Layer Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "644887df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.w = nn.Parameter(torch.ones(cfg.d_model))\n",
    "        self.b = nn.Parameter(torch.zeros(cfg.d_model))\n",
    "    \n",
    "    def forward(self, residual):\n",
    "        # residual: [batch, position, d_model]\n",
    "        reduced = einops.reduce(residual, 'batch position d_model -> batch position', 'mean')\n",
    "\n",
    "        \n",
    "        \n",
    "        centered_res = residual - einops.repeat(reduced, 'batch position -> batch position d_model', d_model=self.cfg.d_model)\n",
    "        \n",
    "        # normalize\n",
    "        scale = einops.reduce(centered_res.pow(2), 'batch position model -> batch position', 'mean') +  self.cfg.layer_norm_eps\n",
    "\n",
    "        \n",
    "        normalized = centered_res / einops.repeat(scale.sqrt(), 'batch position -> batch position d_model', d_model=self.cfg.d_model)\n",
    "\n",
    "        return normalized * self.w + self.b\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3eb769f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n",
      "\n",
      "Input shape: torch.Size([1, 35, 768])\n",
      "Output shape: torch.Size([1, 35, 768])\n",
      "Reference output shape: torch.Size([1, 35, 768])\n",
      "100.00% of the values are correct\n"
     ]
    }
   ],
   "source": [
    "_ = rand_float_test(LayerNorm, [2, 4, 768])\n",
    "_ = load_gpt2_test(LayerNorm, reference_gpt2.ln_final, \"blocks.11.hook_resid_post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222c7050",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1704af53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4])\n",
      "Output shape: torch.Size([2, 4, 768])\n",
      "\n",
      "Input shape: torch.Size([1, 35])\n",
      "Output shape: torch.Size([1, 35, 768])\n",
      "Reference output shape: torch.Size([1, 35, 768])\n",
      "100.00% of the values are correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0514, -0.0277,  0.0499,  ...,  0.0070,  0.1552,  0.1207],\n",
       "         [ 0.1474, -0.0959,  0.1430,  ...,  0.1030, -0.0625, -0.1131],\n",
       "         [ 0.1596, -0.1249,  0.1148,  ...,  0.2558,  0.0196,  0.0145],\n",
       "         ...,\n",
       "         [-0.0393,  0.0050,  0.0421,  ..., -0.0477,  0.0670, -0.0471],\n",
       "         [-0.1488,  0.1519,  0.0056,  ..., -0.3107,  0.2073,  0.0377],\n",
       "         [-0.1101, -0.0393,  0.0331,  ..., -0.1364,  0.0151,  0.0453]]],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Embed(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_E = nn.Parameter(torch.empty((cfg.d_vocab, cfg.d_model)))\n",
    "        nn.init.normal_(self.W_E, std=self.cfg.init_range)\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        # tokens: [batch, position]\n",
    "        return self.W_E[tokens, :]\n",
    "\n",
    "rand_int_test(Embed, [2, 4])\n",
    "load_gpt2_test(Embed, reference_gpt2.embed, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8657a3",
   "metadata": {},
   "source": [
    "## Positional Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fd6a8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4])\n",
      "Tokens: torch.Size([2, 4])\n",
      "pos_embed: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n",
      "\n",
      "Input shape: torch.Size([1, 35])\n",
      "Tokens: torch.Size([1, 35])\n",
      "pos_embed: torch.Size([1, 35, 768])\n",
      "Output shape: torch.Size([1, 35, 768])\n",
      "Reference output shape: torch.Size([1, 35, 768])\n",
      "100.00% of the values are correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.8821e-02, -1.9742e-01,  4.0267e-03,  ..., -4.3044e-02,\n",
       "           2.8267e-02,  5.4490e-02],\n",
       "         [ 2.3959e-02, -5.3792e-02, -9.4879e-02,  ...,  3.4170e-02,\n",
       "           1.0172e-02, -1.5573e-04],\n",
       "         [ 4.2161e-03, -8.4764e-02,  5.4515e-02,  ...,  1.9745e-02,\n",
       "           1.9325e-02, -2.1424e-02],\n",
       "         ...,\n",
       "         [ 4.6277e-04,  2.3037e-02,  4.1227e-02,  ..., -1.9287e-03,\n",
       "          -2.3037e-03, -4.3189e-03],\n",
       "         [-2.7136e-03,  2.1724e-02,  3.9675e-02,  ...,  4.2048e-04,\n",
       "          -4.8160e-03, -9.2252e-04],\n",
       "         [ 6.6815e-03,  2.0595e-02,  3.6596e-02,  ..., -9.5090e-04,\n",
       "          -3.2512e-03, -9.6509e-04]]], grad_fn=<ExpandBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PosEmbed(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_pos = nn.Parameter(torch.empty((cfg.n_ctx, cfg.d_model)))\n",
    "        nn.init.normal_(self.W_pos, std=self.cfg.init_range)\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        if self.cfg.debug: print(\"Tokens:\", tokens.shape)\n",
    "        pos_embed = self.W_pos[:tokens.size(1), :] # [position, d_model]\n",
    "        pos_embed = einops.repeat(pos_embed, \"position d_model -> batch position d_model\", batch=tokens.size(0))\n",
    "        if self.cfg.debug: print(\"pos_embed:\", pos_embed.shape)\n",
    "        return pos_embed\n",
    "\n",
    "rand_int_test(PosEmbed, [2, 4])\n",
    "load_gpt2_test(PosEmbed, reference_gpt2.pos_embed, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2aaf22",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b4d7a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n",
      "\n",
      "Input shape: torch.Size([1, 35, 768])\n",
      "Output shape: torch.Size([1, 35, 768])\n",
      "Reference output shape: torch.Size([1, 35, 768])\n",
      "91.77% of the values are correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3649e+00,  2.1711e+00,  7.0825e+00,  ..., -1.4679e-01,\n",
       "           2.6480e-01,  9.8746e-01],\n",
       "         [-1.3159e+01, -4.1196e+00,  8.6870e+00,  ..., -4.7698e-01,\n",
       "          -2.4685e-01,  3.7986e-01],\n",
       "         [-1.7002e+01,  4.8321e+00, -6.2118e-01,  ..., -7.1945e-01,\n",
       "           1.0781e+00,  5.4464e-01],\n",
       "         ...,\n",
       "         [-1.3211e+01,  7.5175e-01,  8.9662e+00,  ..., -4.2861e-01,\n",
       "           4.6559e-01, -9.4983e-01],\n",
       "         [-1.3922e-03,  6.5740e+00,  1.9785e+01,  ..., -6.7092e-01,\n",
       "          -1.0935e-01,  7.8008e-02],\n",
       "         [-6.0138e+00, -1.8512e-01,  1.8866e+01,  ..., -5.4550e-01,\n",
       "          -4.9667e-02, -1.4721e-01]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_Q = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
    "        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n",
    "        self.b_Q = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
    "        self.W_K = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
    "        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n",
    "        self.b_K = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
    "        self.W_V = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
    "        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n",
    "        self.b_V = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
    "        \n",
    "        self.W_O = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n",
    "        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n",
    "        self.b_O = nn.Parameter(torch.zeros((cfg.d_model)))\n",
    "        \n",
    "        self.register_buffer(\"IGNORE\", torch.tensor(-1e5, dtype=torch.float32))\n",
    "    \n",
    "    def forward(self, normalized_resid_pre):\n",
    "        # normalized_resid_pre: [batch, position, d_model]\n",
    "\n",
    "        q = einsum('batch query_pos d_model, n_head d_model d_head -> batch query_pos n_head d_head', normalized_resid_pre, self.W_Q) + self.b_Q\n",
    "        k = einsum('batch key_pos d_model, n_head d_model d_head -> batch key_pos n_head d_head', normalized_resid_pre, self.W_K) + self.b_K\n",
    "    \n",
    "        attn = einsum('batch query_pos n_head d_head, batch key_pos n_head d_head -> batch n_head query_pos key_pos', q, k)\n",
    "        attn = attn / math.sqrt(self.cfg.d_head) # idk maybe n_heads\n",
    "        attn = self.apply_causal_mask(attn)\n",
    "        attn = attn.softmax(dim=-1)\n",
    "\n",
    "        # take values\n",
    "        v = einsum('batch key_pos d_model, n_head d_model d_head -> batch key_pos n_head d_head', normalized_resid_pre, self.W_V) + self.b_V\n",
    "        \n",
    "        z = einsum('batch key_pos n_head d_head, batch n_head query_pos key_pos -> batch query_pos n_head d_head', v, attn)\n",
    "\n",
    "        return einsum('batch position n_head d_head, n_head d_head d_model -> batch position d_model', z, self.W_O) + self.b_O\n",
    "\n",
    "    \n",
    "    def apply_causal_mask(self, attn_scores):\n",
    "        # attn_scores: [batch, n_heads, query_pos, key_pos]\n",
    "        mask = torch.triu(torch.ones(attn_scores.size(-2), attn_scores.size(-1), device=attn_scores.device), diagonal=1).bool()\n",
    "        attn_scores.masked_fill_(mask, self.IGNORE)\n",
    "        return attn_scores\n",
    "\n",
    "rand_float_test(Attention, [2, 4, 768])\n",
    "load_gpt2_test(Attention, reference_gpt2.blocks[0].attn, cache[\"blocks.0.attn.ln1.hook_normalized\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0638ef7",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f50cf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n",
      "\n",
      "Input shape: torch.Size([1, 35, 768])\n",
      "Output shape: torch.Size([1, 35, 768])\n",
      "Reference output shape: torch.Size([1, 35, 768])\n",
      "100.00% of the values are correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5493,  1.2235,  1.7083,  ...,  0.3605, -0.3244, -1.0762],\n",
       "         [-0.5139,  1.5578,  1.1685,  ...,  0.1968, -0.4189,  0.2061],\n",
       "         [ 0.8885, -0.2943,  1.2722,  ...,  0.1263, -0.1853, -0.6608],\n",
       "         ...,\n",
       "         [ 0.3520,  0.6832,  0.3432,  ...,  0.4583,  0.2621, -1.3458],\n",
       "         [ 1.5537,  1.5894,  0.7426,  ..., -0.2869, -0.6618,  0.4345],\n",
       "         [ 1.1247,  1.8329, -0.5603,  ...,  0.4421, -0.3301, -0.4539]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_in = nn.Parameter(torch.empty((cfg.d_model, cfg.d_mlp)))\n",
    "        nn.init.normal_(self.W_in, std=self.cfg.init_range)\n",
    "        self.b_in = nn.Parameter(torch.zeros((cfg.d_mlp)))\n",
    "        self.W_out = nn.Parameter(torch.empty((cfg.d_mlp, cfg.d_model)))\n",
    "        nn.init.normal_(self.W_out, std=self.cfg.init_range)\n",
    "        self.b_out = nn.Parameter(torch.zeros((cfg.d_model)))\n",
    "    \n",
    "    def forward(self, normalized_resid_mid):\n",
    "        # normalized_resid_mid: [batch, position, d_model]\n",
    "        fir = einsum(\"batch position d_model, d_model d_mlp -> batch position d_mlp\", normalized_resid_mid, self.W_in) + self.b_in\n",
    "        sec = gelu_new(fir)\n",
    "        out = einsum(\"batch position d_model, d_model d_mlp -> batch position d_mlp\", sec, self.W_out) + self.b_out\n",
    "        return out\n",
    "\n",
    "rand_float_test(MLP, [2, 4, 768])\n",
    "load_gpt2_test(MLP, reference_gpt2.blocks[0].mlp, cache[\"blocks.0.ln2.hook_normalized\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea00268",
   "metadata": {},
   "source": [
    "## Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb46b5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n",
      "\n",
      "Input shape: torch.Size([1, 35, 768])\n",
      "Output shape: torch.Size([1, 35, 768])\n",
      "Reference output shape: torch.Size([1, 35, 768])\n",
      "0.01% of the values are correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3642,  0.3787,  0.6980,  ...,  0.2879,  0.4503,  0.1241],\n",
       "         [-0.9123, -0.2621,  0.5932,  ..., -0.5121,  0.3010,  0.7070],\n",
       "         [-0.7729, -2.5320, -1.0277,  ...,  1.9081,  0.8943,  1.1143],\n",
       "         ...,\n",
       "         [-0.7124,  1.3763,  0.1646,  ...,  0.4165,  0.3187, -0.5036],\n",
       "         [-0.5880,  0.8487,  1.4821,  ..., -0.9663, -0.0544,  1.4534],\n",
       "         [ 1.2746, -0.4352,  1.6332,  ..., -0.0121,  0.8610,  0.7087]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.ln1 = LayerNorm(cfg)\n",
    "        self.attn = Attention(cfg)\n",
    "        self.ln2 = LayerNorm(cfg)\n",
    "        self.mlp = MLP(cfg)\n",
    "    \n",
    "    def forward(self, resid_pre):\n",
    "        # resid_pre [batch, position, d_model]\n",
    "        resid_pre = self.ln1(resid_pre)\n",
    "        resid_pre += self.attn(resid_pre)\n",
    "        resid_pre = self.ln2(resid_pre)\n",
    "        return resid_pre + self.mlp(resid_pre)\n",
    "\n",
    "\n",
    "rand_float_test(TransformerBlock, [2, 4, 768])\n",
    "load_gpt2_test(TransformerBlock, reference_gpt2.blocks[0], cache[\"resid_pre\", 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c900c102",
   "metadata": {},
   "source": [
    "## Unembedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fea24ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unembed(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_U = nn.Parameter(torch.empty((cfg.d_model, cfg.d_vocab)))\n",
    "        nn.init.normal_(self.W_U, std=self.cfg.init_range)\n",
    "        self.b_U = nn.Parameter(torch.zeros((cfg.d_vocab), requires_grad=False))\n",
    "    \n",
    "    def forward(self, normalized_resid_final):\n",
    "        # normalized_resid_final [batch, position, d_model]\n",
    "        \"YOUR CODE HERE\"\n",
    "\n",
    "rand_float_test(Unembed, [2, 4, 768])\n",
    "load_gpt2_test(Unembed, reference_gpt2.unembed, cache[\"ln_final.hook_normalized\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c96f842",
   "metadata": {},
   "source": [
    "## Full Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7235840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DemoTransformer(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.embed = Embed(cfg)\n",
    "        self.pos_embed = PosEmbed(cfg)\n",
    "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n",
    "        self.ln_final = LayerNorm(cfg)\n",
    "        self.unembed = Unembed(cfg)\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        # tokens [batch, position]\n",
    "        \"YOUR CODE HERE\"\n",
    "\n",
    "rand_int_test(DemoTransformer, [2, 4])\n",
    "load_gpt2_test(DemoTransformer, reference_gpt2, tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
