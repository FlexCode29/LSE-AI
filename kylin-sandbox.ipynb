{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b9de48f-c597-40d1-87e7-c28d09f21dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import plotly.express as px\n",
    "import torch as t\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import einops\n",
    "from jaxtyping import Int, Float\n",
    "from typing import List, Optional, Tuple\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import webbrowser\n",
    "import gdown\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformer_lens import utils, HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "import circuitsvis as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d005f8b7-2ec1-47cd-818a-3ffbecf3129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_predictions(logits, n_tokens=10):\n",
    "    # Ensure logits is a numpy array for easy manipulation\n",
    "    logits = logits.detach().numpy()\n",
    "    \n",
    "    # Get the last set of logits if logits represents a sequence of predictions\n",
    "    next_token_logits = logits[0, -1] if logits.ndim > 1 else logits\n",
    "    \n",
    "    # Find the indices of the top n_tokens logits\n",
    "    top_tokens = np.argsort(next_token_logits)[-n_tokens:][::-1]\n",
    "    \n",
    "    # Extract the probabilities (or logits) of these top tokens\n",
    "    top_tokens_probs = next_token_logits[top_tokens]\n",
    "    \n",
    "    return top_tokens.tolist(), top_tokens_probs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a082b35c-1c4d-429a-a71f-4df51585b258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# Load a model (eg GPT-2 Small)\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c524019b-dbcc-4152-9bf4-b47139da27b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loss: tensor(2.8293, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    " # Load an ICL sequence\n",
    "sequence = \"\"\"Google decreased revenue by 50% this quarter. // Sell\n",
    "Apple increased revenue by 30% this quarter. // Buy\n",
    "OpenAI increased revenue by 80% this quarter. // Buy\n",
    "Tesla increased revenue by 20% this week. // Buy\n",
    "Ford decreased revenue by 40% this year. //\"\"\"\n",
    "\n",
    "\n",
    "# Run the model and get logits and activations\n",
    "logits, loss = model(sequence, return_type=\"both\")\n",
    "print(\"Model loss:\", loss)\n",
    "\n",
    "# logits, activations = model.run_with_cache(sequence)\n",
    "# print(model.tokenizer.batch_decode(logits.argmax(dim=-1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1be1d638-7613-462d-8151-9ee2f3c4a7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([11763, 25688, 9842, 12324, 198, 2822, 3677, 2094, 1514, 17329],\n",
       " [18.217296600341797,\n",
       "  15.746993064880371,\n",
       "  13.62832260131836,\n",
       "  13.515268325805664,\n",
       "  13.00149154663086,\n",
       "  12.990470886230469,\n",
       "  12.637158393859863,\n",
       "  12.620811462402344,\n",
       "  12.61329460144043,\n",
       "  12.570591926574707])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_tokens, top_probs = top_predictions(logits)\n",
    "top_tokens, top_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecc72242-7bdd-44cd-b871-64402091e53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Buy',\n",
       " ' Sell',\n",
       " ' Bu',\n",
       " ' Sold',\n",
       " '\\n',\n",
       " ' buy',\n",
       " ' sell',\n",
       " ' Don',\n",
       " ' Go',\n",
       " ' Sales']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer.batch_decode(top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392d013-f820-4802-8a0e-1e2247fc3c12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
