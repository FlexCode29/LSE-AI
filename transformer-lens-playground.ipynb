{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b9de48f-c597-40d1-87e7-c28d09f21dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import plotly.express as px\n",
    "import torch as t\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import einops\n",
    "from jaxtyping import Int, Float\n",
    "from typing import List, Optional, Tuple\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import webbrowser\n",
    "import gdown\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformer_lens import utils, HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "import circuitsvis as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d005f8b7-2ec1-47cd-818a-3ffbecf3129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_predictions(logits, n_tokens=10):\n",
    "    # Ensure logits is a numpy array for easy manipulation\n",
    "    logits = logits.detach().numpy()\n",
    "    \n",
    "    # Get the last set of logits if logits represents a sequence of predictions\n",
    "    next_token_logits = logits[0, -1] if logits.ndim > 1 else logits\n",
    "    \n",
    "    # Find the indices of the top n_tokens logits\n",
    "    top_tokens = np.argsort(next_token_logits)[-n_tokens:][::-1]\n",
    "    \n",
    "    # Extract the probabilities (or logits) of these top tokens\n",
    "    top_tokens_probs = next_token_logits[top_tokens]\n",
    "    \n",
    "    return top_tokens.tolist(), top_tokens_probs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a082b35c-1c4d-429a-a71f-4df51585b258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# Load a model (eg GPT-2 Small)\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c524019b-dbcc-4152-9bf4-b47139da27b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loss: tensor(4.7088, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    " # Load an ICL sequence\n",
    "sequence = \"\"\"Circulation revenue has increased by 5% in Finland. // Positive\n",
    "Panostaja did not disclose the purchase price. // Neutral\n",
    "Paying off the national debt will be extremely painful. // Negative\n",
    "The company anticipated its operating profit to improve. //\"\"\"\n",
    "\n",
    "\n",
    "# Run the model and get logits and activations\n",
    "logits, loss = model(sequence, return_type=\"both\")\n",
    "print(\"Model loss:\", loss)\n",
    "\n",
    "# logits, activations = model.run_with_cache(sequence)\n",
    "# print(model.tokenizer.batch_decode(logits.argmax(dim=-1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce5709c0-3c99-48ed-9227-8f8f9fc6eb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 7.5261, 11.1214,  7.8919,  ..., -3.1299, -3.3873,  8.5934],\n",
       "         [ 5.7127,  4.4277,  5.2648,  ..., -1.0044, -2.2531,  4.2533],\n",
       "         [ 6.7858,  6.5628,  4.9398,  ..., -0.8247, -2.1811,  6.5063],\n",
       "         ...,\n",
       "         [ 8.4301,  8.2613, -0.4150,  ..., -0.0392, -1.8792,  8.2315],\n",
       "         [ 3.2394,  5.5793,  4.1027,  ..., -3.4902, -3.4566, 11.1141],\n",
       "         [ 3.9121,  6.0483,  3.1660,  ..., -4.0318, -5.2399,  7.6598]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1be1d638-7613-462d-8151-9ee2f3c4a7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([25627, 33733, 36183, 4633, 8500, 3967, 13496, 9576, 13535, 198],\n",
       " [16.663612365722656,\n",
       "  15.992452621459961,\n",
       "  15.790984153747559,\n",
       "  12.728263854980469,\n",
       "  12.549846649169922,\n",
       "  12.500576972961426,\n",
       "  11.822123527526855,\n",
       "  10.926145553588867,\n",
       "  10.884611129760742,\n",
       "  10.776315689086914])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_tokens, top_probs = top_predictions(logits)\n",
    "top_tokens, top_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecc72242-7bdd-44cd-b871-64402091e53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Neutral',\n",
       " ' Positive',\n",
       " ' Negative',\n",
       " ' negative',\n",
       " ' neutral',\n",
       " ' positive',\n",
       " ' Neg',\n",
       " ' Very',\n",
       " ' Strong',\n",
       " '\\n']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer.batch_decode(top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392d013-f820-4802-8a0e-1e2247fc3c12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
