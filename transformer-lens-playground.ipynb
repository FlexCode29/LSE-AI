{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b9de48f-c597-40d1-87e7-c28d09f21dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import plotly.express as px\n",
    "import torch as t\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import einops\n",
    "from jaxtyping import Int, Float\n",
    "from typing import List, Optional, Tuple\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import webbrowser\n",
    "import gdown\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformer_lens import utils, HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "import circuitsvis as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d005f8b7-2ec1-47cd-818a-3ffbecf3129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_predictions(logits, n_tokens=10):\n",
    "    # Ensure logits is a numpy array for easy manipulation\n",
    "    logits = logits.detach().numpy()\n",
    "    \n",
    "    # Get the last set of logits if logits represents a sequence of predictions\n",
    "    next_token_logits = logits[0, -1] if logits.ndim > 1 else logits\n",
    "    \n",
    "    # Find the indices of the top n_tokens logits\n",
    "    top_tokens = np.argsort(next_token_logits)[-n_tokens:][::-1]\n",
    "    \n",
    "    # Extract the probabilities (or logits) of these top tokens\n",
    "    top_tokens_probs = next_token_logits[top_tokens]\n",
    "    \n",
    "    return top_tokens.tolist(), top_tokens_probs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a082b35c-1c4d-429a-a71f-4df51585b258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# Load a model (eg GPT-2 Small)\n",
    "model = HookedTransformer.from_pretrained(\"gpt2-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c524019b-dbcc-4152-9bf4-b47139da27b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loss: tensor(4.1481, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    " # Load an ICL sequence\n",
    "sequence = \"\"\"Google missed earning by 10% this quarter. // Sell\n",
    "Apple increased revenue by 5% this quarter. // Buy\n",
    "OpenAI has fired the CEO Sam Altman after the board voted. // Sell\n",
    "Tesla improved revenue by 20% after meeting with clients this week. // Buy\n",
    "Ford anticipated its profit will decrease by 50%. //\"\"\"\n",
    "\n",
    "\n",
    "# Run the model and get logits and activations\n",
    "logits, loss = model(sequence, return_type=\"both\")\n",
    "print(\"Model loss:\", loss)\n",
    "\n",
    "# logits, activations = model.run_with_cache(sequence)\n",
    "# print(model.tokenizer.batch_decode(logits.argmax(dim=-1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1be1d638-7613-462d-8151-9ee2f3c4a7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([25688, 11763, 12324, 3677, 16467, 2822, 198, 8734, 16981, 3497],\n",
       " [17.737926483154297,\n",
       "  17.673601150512695,\n",
       "  13.972225189208984,\n",
       "  13.425271987915039,\n",
       "  12.479013442993164,\n",
       "  12.439650535583496,\n",
       "  12.399359703063965,\n",
       "  12.196646690368652,\n",
       "  11.861695289611816,\n",
       "  11.84620189666748])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_tokens, top_probs = top_predictions(logits)\n",
    "top_tokens, top_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecc72242-7bdd-44cd-b871-64402091e53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Sell',\n",
       " ' Buy',\n",
       " ' Sold',\n",
       " ' sell',\n",
       " ' Sale',\n",
       " ' buy',\n",
       " '\\n',\n",
       " ' Share',\n",
       " ' Ask',\n",
       " ' Get']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer.batch_decode(top_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392d013-f820-4802-8a0e-1e2247fc3c12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
